{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a387d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63490029",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgSize = 28\n",
    "classes = 10\n",
    "channels = 1\n",
    "latenDim = 100\n",
    "epochNumber = 50\n",
    "lr = 2e-4\n",
    "batchSize = 32\n",
    "zDimension = 100\n",
    "imgResize = 28\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc60a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f00cbe",
   "metadata": {},
   "source": [
    "# Class Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92654467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, classes, channels, imgSize, latenDim):\n",
    "        super(Generator, self).__init__();\n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.imgSize = imgSize\n",
    "        self.latenDim = latenDim\n",
    "        self.imgShape = (self.channels, self.imgSize, self.imgSize)\n",
    "        self.labelEmbedding = nn.Embedding(self.classes, self.classes)\n",
    "        \n",
    "        self.interLayers = nn.Sequential(\n",
    "            self._linearBlock(self.latenDim + self.classes, 128),\n",
    "            self._linearBlock(128, 256),\n",
    "            self._linearBlock(256, 512),\n",
    "            self._linearBlock(512, 1024)\n",
    "        )\n",
    "        \n",
    "        # Converting 1024 to 784 hidden layers for converting back it to 1x28x28\n",
    "        self.linear = nn.Linear(1024, 784)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        \n",
    "    def _linearBlock(self, inputHiddens, outputHiddens):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features=inputHiddens, out_features=outputHiddens),\n",
    "            nn.BatchNorm1d(outputHiddens),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "    def forward(self, noise, labels):\n",
    "        #noise -> [B, 100] labels->[B]\n",
    "        print(noise.shape, labels.shape)\n",
    "        ll = self.labelEmbedding(labels)\n",
    "        z = torch.concat([noise, ll], dim=1)\n",
    "        x = self.interLayers(z)\n",
    "        return self.tanh(self.linear(x)) # Output -> [B,28*28] = [B, 784]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(classes, channels,imgSize, latenDim).to(device)\n",
    "# outGen = gen(torch.randn(2,100), torch.randint(low=0, high=10, size=(2,)))\n",
    "# outGen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6abd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint(low=0, high=10, size=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f924195d",
   "metadata": {},
   "source": [
    "# Class Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d743e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, classes, channels, imgSize, latentDim):\n",
    "        super(Discriminator, self).__init__();\n",
    "        \n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.imgSize = imgSize\n",
    "        self.latentDim = latenDim\n",
    "        self.imgShape = (self.channels, self.imgSize, self.imgSize)\n",
    "        self.labelEmbedding = nn.Embedding(self.classes, self.classes)\n",
    "        \n",
    "        self.interLayers = nn.Sequential(\n",
    "            self._linearBlock(self.classes+int(np.prod(self.imgShape)), 1024),\n",
    "            self._linearBlock(1024, 512),\n",
    "            self._linearBlock(512, 256),\n",
    "        )\n",
    "        self.linear1 = nn.Linear(256,128)\n",
    "        self.linear2 = nn.Linear(128,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def _linearBlock(self, inHiddens, outHiddens):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features=inHiddens, out_features=outHiddens),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        # x->[B, 784] LABELS -> [B]\n",
    "        ll = self.labelEmbedding(labels)\n",
    "        y = torch.concat([x, ll], dim=1) \n",
    "        outputs = self.interLayers(y)\n",
    "        return self.sigmoid(self.linear2(self.linear1(outputs))) # output -> [B,1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4479a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(classes, channels, imgSize, latenDim).to(device)\n",
    "# discOut = disc(torch.randn(2,784), torch.randint(0, classes, size=(2,)))\n",
    "# discOut.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f69d57",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4003f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(imgResize),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f72a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.MNIST(root=\"\", download=True, transform=transforms)\n",
    "dataloader = DataLoader(data, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243d11d",
   "metadata": {},
   "source": [
    "# Loss Function, Optimiser and Noise Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1fe951",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimDisc = torch.optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimGen = torch.optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Noise Vector\n",
    "noiseVectotForGen = torch.randn(batchSize, zDimension, 1, 1, device=device)\n",
    "noiseVectorForGenTesting = torch.randn(batchSize, zDimension, 1, 1, device=device)\n",
    "\n",
    "fig=plt.figure(figsize=(6, 6))\n",
    "# Define row and cols in the figure\n",
    "rows, cols = 2, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c143a",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ea1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiscLoss = []\n",
    "GenLoss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed803f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
