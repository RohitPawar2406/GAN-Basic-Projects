{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import utilsFunction\n",
    "from model import Generator\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramters\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataPath = ''\n",
    "outPath = \"output/\"\n",
    "\n",
    "batchSize = 32\n",
    "imgChannels = 1\n",
    "zDimension = 100\n",
    "gDimension = 64\n",
    "discDimension = 64\n",
    "\n",
    "imgResize = 64\n",
    "\n",
    "epochNumber = 50\n",
    "lr = 2e-4\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator and Dicriminator Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latenDim, featuresGen, outputChannels):\n",
    "        super(Generator, self).__init__();\n",
    "        \n",
    "        self.gen = nn.Sequential(\n",
    "            # Input -> [B,100,1,1]\n",
    "            \n",
    "            # First Layer\n",
    "            nn.ConvTranspose2d(latenDim, featuresGen*8, 4, 1, 0),\n",
    "            nn.BatchNorm2d(featuresGen*8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Second Layer\n",
    "            nn.ConvTranspose2d(featuresGen*8, featuresGen*4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(featuresGen*4),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Third layer\n",
    "            nn.ConvTranspose2d(featuresGen*4, featuresGen*2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(featuresGen*2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Fourth Layer\n",
    "            nn.ConvTranspose2d(featuresGen*2, featuresGen, 4, 2, 1),\n",
    "            nn.BatchNorm2d(featuresGen),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.ConvTranspose2d(featuresGen, outputChannels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, imgChannels, featuresDisc) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.disc = nn.Sequential(\n",
    "            # Input -> [B,C, 64, 64]\n",
    "            nn.Conv2d(imgChannels, featuresDisc, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 2nd Layer\n",
    "            nn.Conv2d(featuresDisc, featuresDisc*2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(featuresDisc*2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 3rd Layer\n",
    "            nn.Conv2d(featuresDisc*2, featuresDisc*4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(featuresDisc*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 4th Layer\n",
    "            nn.Conv2d(featuresDisc*4, featuresDisc*8, 4, 2, 1),\n",
    "            nn.BatchNorm2d(featuresDisc*8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # Output Layer\n",
    "            nn.Conv2d(featuresDisc*8, 1, 4, 1, 0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(zDimension, gDimension, imgChannels).to(device)\n",
    "disc = Discriminator(imgChannels, discDimension).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputGen = gen(torch.randn(2,100,1,1, device=device))\n",
    "outputDisc = disc(torch.randn(2,1,64,64, device=device))\n",
    "assert outputGen.shape[1]==imgChannels, \"Image Channels not match to parameters\"\n",
    "\n",
    "# outputGen.shape # [2, 1, 64, 64]\n",
    "# outputDisc.shape, outputDisc #[2, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(imgResize),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root = '', download=False, transform=transforms)\n",
    "assert dataset,\"dataset null value\"\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add a pin_memory=True argument when\n",
    "calling torch.utils.data.DataLoader() on small datasets, which will\n",
    "make sure data is stored at fixed GPU memory addresses and thus\n",
    "increase the data loading speed during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions and optimisers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizerDisc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerGen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "noiseVectotForGen = torch.randn(batchSize, zDimension, 1, 1, device=device)\n",
    "noiseVectorForGenTesting = torch.randn(batchSize, zDimension, 1, 1, device=device)\n",
    "\n",
    "fig=plt.figure(figsize=(6, 6))\n",
    "# Define row and cols in the figure\n",
    "rows, cols = 2, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiscLoss = []\n",
    "GenLoss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,epochNumber):\n",
    "    print(f\"=================================== EPOCH:{i}======================================================\")\n",
    "    \n",
    "    start = time.time()\n",
    "    trainDiscLoss = 0\n",
    "    trainGenLoss = 0\n",
    "    for batch,(data,_) in enumerate(dataloader):\n",
    "        ## Train Discriminator: max log(D(x)) + log(1-D(G(z)))\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizerDisc.zero_grad()\n",
    "        # 1) Train Discriminator with real data and recongnize it as real i.e., max log(D(x)) \n",
    "        discRealOutput = disc(data) #output -> [B,1,1,1]\n",
    "        discLossReal = criterion(discRealOutput, torch.ones_like(discRealOutput))\n",
    "        \n",
    "        # 2)Train the discriminator with the fake data and recognize it as fake i.e., max log(1-D(G(z)))\n",
    "        genfakeOutput = gen(noiseVectotForGen) #output ->[b,imgChannels, 64, 64]\n",
    "        discFakeOuput = disc(genfakeOutput.detach()) ##output -> [B,1,1,1]\n",
    "        discLossFake = criterion(discFakeOuput, torch.zeros_like(discFakeOuput))\n",
    "        \n",
    "        \n",
    "        finalDiscLoss = discLossReal + discLossFake\n",
    "        trainDiscLoss+=finalDiscLoss.item()\n",
    "        finalDiscLoss.backward()\n",
    "        optimizerDisc.step()\n",
    "        \n",
    "        # 3)Train the generator with the fake data and recognize it as real i.e., min log(D(G(z)))\n",
    "        optimizerGen.zero_grad()\n",
    "        discReal = disc(genfakeOutput)\n",
    "        lossGenerator = criterion(discReal, torch.ones_like(discRealOutput))\n",
    "        trainGenLoss+=lossGenerator.item()\n",
    "        lossGenerator.backward()\n",
    "        optimizerGen.step()\n",
    "    DiscLoss.append(trainDiscLoss/len(dataloader))\n",
    "    GenLoss.append(trainGenLoss/len(dataloader))\n",
    "    print(f\"Discriminator Loss:{trainDiscLoss/(len(dataloader))} and Generator Loss:{trainGenLoss/len(dataloader)}\")\n",
    "        \n",
    "    # After every 3 epochs will check results\n",
    "    if i%5==0:\n",
    "        with torch.no_grad():\n",
    "            fake = gen(noiseVectorForGenTesting) # [b,3,64,64]\n",
    "            imgGridReal = torchvision.utils.make_grid(data[:5], normalize=True,nrow=5)\n",
    "            imgGridFake = torchvision.utils.make_grid(fake[:5], normalize=True,nrow=5)\n",
    "            images = []\n",
    "            images.append(imgGridFake)\n",
    "            images.append(imgGridReal)\n",
    "            for j in range(0, cols*rows):\n",
    "                fig.add_subplot(rows, cols, j+1)\n",
    "                a = images[j].permute(1,2,0)\n",
    "                b = a.detach().cpu().numpy()\n",
    "                \n",
    "                plt.imshow(b)\n",
    "                plt.show()\n",
    "    end = time.time()\n",
    "    print(f\"Time duration for Epoch no: {i} is {end-start}\")\n",
    "    print(f\"=====================================================================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(),f\"output/generatorEpoch{i}.pth\")\n",
    "torch.save(disc.state_dict(),f\"output/discriminatorEpoch{i}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i+1 for i in range(0,epochNumber)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot lines\n",
    "plt.plot(x, DiscLoss, label = \"Discriminator Loss\")\n",
    "plt.plot(x, GenLoss, label = \"Generator Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
